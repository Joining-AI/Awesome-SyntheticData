# LeanReasoner: Boosting Complex Logical Reasoning with Lean

[原链接](https://arxiv.org/html/2403.13312v1)

### 摘要
自动形式化（Autoformalization）是将自然语言数学转换为形式语言的过程，具有显著的潜力来推动数学推理的发展。然而，现有的努力主要集中在拥有大量在线语料的形式语言上，并且难以跟上快速发展的语言，如 Lean 4。为了解决这个问题，我们提出了一个新的基准 Formalization for Lean 4 (FormL4)，用于评估大型语言模型（LLMs）的自动形式化能力。这个基准包含了对问题、答案、形式陈述和证明的全面评估。此外，我们引入了一个过程监督验证器（PSV）模型，该模型利用 Lean 4 编译器的精确反馈来增强自动形式化。我们的实验表明，PSV 方法能够改进自动形式化，使用更少的过滤训练数据实现更高的准确性。此外，当使用包含详细过程信息的数据进行微调时，PSV 可以更有效地利用这些数据，从而显著提升 Lean 4 的自动形式化能力。我们的数据集和代码可在 https://github.com/rookie-joe/PDA 获取。

### 引言
自动形式化是将自然语言数学自动转换为形式语言的任务，具有革新数学推理的巨大潜力。它减少了形式化的高成本，并弥合了自动数学推理研究与大量自然语言数学知识之间的差距。

最近大型语言模型（LLMs）的进展显示出其在广泛任务中的强大能力，为自动形式化开辟了令人兴奋的可能性。尽管研究人员已经探索了使用少样本提示或在包含非正式和正式数学数据的大规模数据集上训练 LLMs，现有的努力仍局限于拥有大量在线语料的形式语言，例如 Lean 3。然而，社区最近将重点转移到 Lean 4，这是一种新的 Lean 定理证明器版本，解决了以前的限制并引入了用于高效编程的新功能。

Lean 4 的快速发展对自动形式化提出了重大挑战，因为跟上语言的不断变化的语法、语义、库和其他方面需要大量的专业知识和与社区的持续互动。这个挑战不仅对人类专家而且对 LLMs 都适用，因为缺乏专门针对 Lean 4 的训练数据和基准限制了它们的进展。为了解决这一问题，我们提出了一个新的基准，Formalization for Lean 4 (FormL4)，专门设计用于评估 LLMs 在 Lean 4 中的自动形式化能力。FormL4 包括问题、答案、形式陈述和证明，提供了对 LLMs 的全面评估。与现有数据集 MMA 不同，FormL4 提供了从自然语言问题和答案到 Lean 4 中的陈述和证明的“完整”自动形式化。这更具挑战性，因为它需要理解 Lean 4 的语法和每个证明中涉及的推理步骤。

形式语言的一个关键优势在于它们的编译器可以提供关于生成的证明的详细步骤级信息。通过 FormL4，我们可以充分利用 Lean 4 编译器的反馈，这种反馈更有价值，因为它包括语法检查和推理验证。这与仅关注翻译陈述而不包括证明的方法形成对比。编译器的过程信息为数学推理过程提供了宝贵的见解。最近的研究表明，过程信息在增强非正式语言的数学推理方面具有潜力。

基于这些进展，我们提出利用 Lean 4 编译器自然提供的精确反馈来改进自动形式化，如图1所示。我们的广泛实验表明，过程监督验证器（PSV）能够显著提升自动形式化器的性能，使其在使用更少过滤训练数据的情况下实现更高的自动形式化性能。此外，当 PSV 使用包含详细过程信息的高质量训练数据进行微调时，它可以更有效地利用这些数据，从而进一步显著提升自动形式化。我们的主要贡献如下：

- 我们构建了一个用于评估 Lean 4 中自动形式化的先驱数据集 FormL4，涵盖从自然语言问题到形式证明的完整过程。
- 我们提出了一种方法，利用形式语言的力量提供关于推理过程的精确反馈，从而增强 LLMs 的自动形式化能力。
- 我们进行了全面研究，旨在弥合 Lean 4 中非正式和正式推理之间的差距。

#### 图1说明
图1展示了基于 FormL4 训练的过程驱动自动形式化框架，并通过过程监督验证器（PSV）进一步增强。具体地，图中展示了四个主要过程：（1）通过提示 GPT-4 对从 Mathlib 4 中提取的定理进行非形式化，构建 FormL4 基准；（2）在 FormL4 上训练自动形式化模型，输出结果发送至 Lean 4 编译器以获得自动反馈；（3）编译反馈可以为自动形式化器提供过程级注释，用于训练有效的 PSV 模型；（4）为了进一步增强，自动形式化器随后通过验证器的反馈进行微调，而验证器可以从改进后的自动形式化器提供的高质量输出数据中再次受益。

### 相关工作
**使用 LLMs 进行自动形式化**
自动形式化是自动将非正式定理和证明转换为机器可验证格式的任务。早期的方法采用神经机器翻译方法将文本翻译为 Mizar 语言。最近 LLMs 的进展为自动形式化开辟了新可能性。研究人员探索了使用少样本提示使 LLMs 将数学问题翻译为形式格式，包括 Isabelle 和 Lean。其他研究采用了更结构化的方法来完成此任务。特别是，DSP 系统利用 LLMs 起草非正式证明并将其映射为形式化草图，使用自动定理证明系统填补证明草图中的缺失细节。此外，有一系列研究专注于在包含非正式和正式数学数据的大规模数据集上训练 LLMs，以评估其在自动形式化中的表现。与现有方法常常忽略 ITPs 中的详细编译信息不同，我们提出的方法利用 Lean 4 编译器的过程反馈来进一步提高 LLMs 的自动形式化能力。

**过程和结果监督**
最近的努力集中在通过验证器增强 LLMs 的数学推理能力，从多个候选答案中选择最佳答案。验证器主要有两种类型：结果监督验证器（OSV）和过程监督验证器（PSV）。OSV 基于最终答案的信号进行监督，而 PSV 则提供详细的反馈，评估单个推理步骤。尽管标注成本高昂，PSV 具有多个优势，使其优于 OSV。PSV 可以通过精确定位错误位置提供细粒度反馈，对于强化学习和自动纠正非常有价值。为减轻大量人工标注，最近的方法提出了一种使用蒙特卡洛树搜索的机器标注框架。这一标注过程需要大量计算资源，可能限制其使用。我们的方法利用形式语言自然提供的精确反馈，能够自动进行过程标注，无需大量人工或机器标注成本。

### FormL4：数据集构建
Lean 4 的快速发展，一种比其前身 Lean 3 具有显著改进的强大形式语言，迫切需要一个专门的基准来评估这一新环境中的自动形式化能力。现有数据集 MMA 主要集中在将问题翻译为陈述，忽略了将非正式解决方案翻译为证明的关键步骤。这一限制阻碍了充分利用 Lean 4 编译器的完整反馈，该编译器可以检查语法并验证证明中的推理。

为解决这一问题，我们引入了专门设计用于评估完整自动形式化过程的 FormL4。FormL4 超越了陈述翻译，涵盖了问题、答案、形式陈述和证明。这种全面的方法使得能够更准确地评估 LLM 理解 Lean 4 语法并在语言框架内进行逻辑推理的能力。在本节中，我们将介绍如何创建高质量的并行语料库（第3.1节）、保证质量（第3.2节）和拆分数据（第3.3节）。

#### 3.1 非形式化
我们利用 GPT-4 自动生成形式化数学陈述及其证明（形式化）的非正式描述。我们的方法超越了先前的工作，旨在将形式化内容的各个方面（陈述和证明）转换为每个数据点的自然语言。这是一个更具挑战性和计算成本更高的任务，要求 GPT-4 理解 Lean 4 的语法和每个证明中的逻辑推理步骤。

由于 GPT-4 直接生成 Lean 4 代码的能力有限（形式化比非形式化更难），我们从 mathlib4 库中提取用 Lean 4 格式编写的已建立定理（包括陈述和证明），并将它们输入 GPT-4 进行非形式化为自然语言描述。值得注意的是，Lean 4 中的 mathlib4 是可用的最广泛的形式数学库

之一。我们提供了具体的指示，提示 GPT-4 将这些定理转换为自然语言问题和答案，详见附录 D。

#### 3.2 策展过程
**预处理**
我们首先从 Mathlib 4 中提取 70,000 个定理，包括它们的陈述和证明。此过程基于 LeanDojo 的脚本，但进行了某些修改。我们采用 LeanDojo 代码从 Mathlib 4 中搜索并提取定理。然而，与原来专注于提取定理名称和策略用于定理证明不同，我们提取了陈述和证明的完整内容。我们不减少证明步骤，旨在提供全面的内容以改进自动形式化。

我们在证明中保留了“#align”命令，该命令由 Mathport 用于连接 Lean 3 名称到 Lean 4 名称。此包含旨在促进 GPT-4 在数据构建过程中的非形式化，因为我们假设 GPT-4 如果有与更熟悉的 Lean 3 语言的联系，将更好地理解 Lean 4 语言。

**后处理**
我们对 GPT-4 非形式化所得数据进行手动和自动筛选，确保提供高质量的自动形式化训练和测试数据。更多细节见附录 H.2。

我们提供一个“定理环境”，包括每个定理的全部依赖和前提，便于更容易的编译。具体来说，只需要将“定理环境”与自动形式化结果连接起来即可验证后者，无需深入研究 Mathlib 的细节。我们认为这种方法简化了编译过程。

#### 表1：FormL4 统计
测试集不一定需要 Lean 4 的地面真实陈述和证明，因为自动形式化输出可以通过编译器验证。实际测试集仅包含自然语言查询和答案，没有任何对应的 Lean 4 陈述。

| 数据集    | 大小   | Lean 4        | 自然语言          |
|-----------|--------|---------------|-------------------|
|           | # Chars, State. & Proof | # Chars, Q & A    |
| 平均      | 中位数 | 最小值        | 最大值            |
| 训练      | 14,510 | 210           | 179               | 101  | 5515  | 1900 | 1905 | 449  | 5706  |
| 随机测试  | 970    | 214           | 180               | 103  | 3242  | 1918 | 1921 | 677  | 4681  |
| 基础测试  | 981    | 205           | 165               | 111  | 2882  | 1781 | 1775 | 481  | 4856  |
| 实际测试  | 1,000  | -             | -                 | -    | -     | 893  | 763  | 401  | 3812  |

#### 3.3 数据集拆分
我们首先创建一个训练集和一个随机测试集，用于训练和评估 LLMs。两个集合都是通过从提取的 Lean 4 源文件中抽取定理（包括其陈述和证明）构建的，抽取后不放回池中。一个示例见附录 E。除了随机测试集外，我们还包括一个基础测试集和一个实际测试集以进行更全面的评估。基础测试集评估模型自动形式化基本定理的能力，几乎不依赖先验知识或已建立的引理。这些定理通常出现在像 Mathlib/Geometry/Euclidean/Basic.lean 这样的文件中，建立了基本的几何概念并证明了关于实内积空间和欧几里得仿射空间的简单结果。此外，我们通过从 Arithmo 测试集中收集 1000 个自然语言数学问题和答案构建实际测试集。表1详细列出了 FormL4 的统计数据，包括 Lean 4 和自然语言字符长度的数据点数量。有关数据集拆分和实际测试集环境的详细信息见附录 H。

**3.4 结果解释器**
如果正确答案是“未知”，我们仅在既不能证明“真”也不能证明“假”的情况下将结果视为正确。本研究中调查的所有数据集只包含唯一正确答案的问题。因此，如果证明系统验证了多个选项，则立即将响应标记为不正确。

**4 实验设置**
我们现在描述我们的实验设置：用于评估和模型训练的数据集以及模型训练的详细信息。

**4.1 评估数据**
在我们的评估中，我们使用了两个常见的逻辑推理数据集作为测试平台：

**ProofWriter**：这个演绎逻辑推理数据集以直观的语言形式呈现问题。我们采用了Pan等人（2023）提出的开放世界假设（OWA）子集，其中每个实例由{问题，目标}配对组成。每对的标签包含真、假或未知。它包括基于所需推理深度的五个部分。我们重点关注最具挑战性的深度5子集。为了公平比较Logic-LM，我们使用了相同的600个样本测试，确保标签分布均匀。

**FOLIO**：与ProofWriter不同，FOLIO使用一阶逻辑构建。这增加了证明部分的复杂性。该数据集还以更自然的措辞呈现问题，关系也复杂得多。如此结合高级逻辑和丰富的语言结构，使得FOLIO中的形式化任务比ProofWriter难得多。对于我们的分析，我们使用了整个FOLIO测试集，共包含204个示例。

**4.2 领域适应的训练数据**
关于模型训练的数据，我们收集了ProofWriter的100个定理证明和FOLIO的27个定理证明，其中每个问题的证明要么是手动注释的，要么是从GPT-4生成的成功证明中收集的。数据收集大约花了八天时间。

在数据注释过程中，我们采用了两种不同的方法来构建证明。一种方法模仿了简单的策略，包括所有中间步骤和引理的详细过程，类似于我们在接到定理证明任务时可能采用的方式。相反，第二种方法类似于mathlib中的证明格式。我们通过减少中间引理的数量并将多个策略组合成一个复合策略，生成相同问题的更简洁的证明。为同一问题提供两种注释的目的是检查注释风格对下游逻辑推理的影响。在接下来的实验中，我们使用Intuitive（直观）指代第一种注释风格，Concise（简洁）指代第二种注释风格。附录C中有一个示例。

尽管收集到的数据有限，但逻辑推理的推理模式可能与数学推理中发现的模式相似，这些模式可能在预训练期间学到。数据收集的主要目的是领域适应，从数学推理转移到自然语言逻辑推理。

**4.3 模型训练**
我们使用与ReProver论文中相同的模型结构进行预训练，即Google的Byte-T5（Xue等，2022）。我们还试验了在mathlib上预训练的LeanDoJo的预训练ReProver（Yang等，2023）。微调我们收集的数据大约花了六个小时，使用了一台A100 40G。超参数与原始LeanDoJo论文中的相同。

**5 结果**
我们展示了实验结果，包括基于提示的基线的检查、LeanReasoner的实验结果以及我们工作与其他基线的比较。

| 模型 | ProofWriter | FOLIO |
| --- | --- | --- |
| Formalize | Prove | Answer | Formalize | Prove | Answer |
| GPT-4 Base | 94% | 15% | 80% | 60% | 10% | 35% |
| GPT-4 Base Comments | 99% | 15% | 80% | 75% | 15% | 35% |
| GPT-4 Base Separate | 95% | 5% | 75% | 60% | 10% | 40% |
| GPT-3 Base Comments | 77% | 12% | 63% | 45% | 10% | 35% |
| Logic-LM | 98% | 75.5% | 74% | 65% | 69.2% | 55% |

表1：通过OpenAI语言模型API对100个ProofWriter样本和40个FOLIO样本进行形式化、证明和答案选择的准确性，使用手动注释。‘GPT-4 Base’作为我们的基线，其中少样例包括单个提示中的形式化和证明生成。在‘GPT-4 Base Comments’中，我们在Lean代码中逐行添加注释来增强这些样例。对于‘GPT-4 Base Separate’，我们将任务分为两个部分，使用单独的提示进行形式化和证明生成。为了简化，我们在评估Logic-LM时没有使用自我改进技术。

**5.1 基于提示的基线**
由于没有自动方法来验证形式化的准确性，我们手动检查了形式化的结果，以确定在形式化或证明生成阶段是否发生错误。在此检查中，只有正确捕捉每个事实、公理和规则的形式化才被视为准确。我们手动检查了ProofWriter验证集的100个问题和FOLIO训练集的40个问题。结果总结在表1中。

**形式化准确率的比较。**
ProofWriter的形式化准确率远高于FOLIO。这可以归因于其语言结构较简单。对于FOLIO，尽管使用LLM进行形式化有助于从自然语言上下文中过滤掉不必要的细节，但仍然存在一些常见的错误模式。我们在附录B中使用从各种错误实例中派生的综合样本，说明了典型的GPT-4错误模式。有趣的是，Lean的形式化准确率与Logic-LM中的Prolog和FOL一致。这种一致性突显了Lean的多功能性，使其能够在单一框架内统一表示不同类型的问题。

**添加文本注释可以提高形式化准确率。**
我们观察到，当形式化代码与从上下文中提取的描述性文本注释配对时，结果有所改善。这种方法进一步将形式化任务分为两个子任务：1）将文本上下文与形式化代码链接起来；2）基于先前的文本上下文生成形式化代码。这些文本提示作为原始文本和形式化代码之间的桥梁，增强了形式化的性能。

**GPT-3在形式化方面的表现不如GPT-4。**
GPT-3和GPT-4在表现上的区别显而易见。虽然对较简单问题的形式化是一样的，但GPT-3在处理复杂逻辑和复杂问题时表现不佳。因此，我们选择不在进一步的测试中使用GPT-3。此外，我们还试验了CodeLLAMA模型家族，用于类似任务，但发现其形式化准确率显著低于GPT-3，在ProofWriter上的准确率不足30%。

**基于提示的基线的证明准确率非常低。**
表中的证明准确率部分由生成的证明是否能在Lean中成功验证决定。如果问题的形式化作为定理是正确的，并且证明可以在没有任何错误或警告的情况下验证，那么我们可以将证明视为有效。然而，生成的证明的准确率非常低。问题可能出在分配给大型语言模型的任务太多，难以在单个提示中解决这两者。尽管我们努力将形式化和证明分开，但结果仍然令人失望，这突显了GPT-3和GPT-4在生成正确Lean证明方面的困难。有趣的是，Logic-LM的证明准确率不如预期高。在复制他们的代码时，我们发现他们选择的求解器Pyke并不理想，在有多个搜索路径时难以找到答案，某些路径可能导致循环。

**基于提示的基线的答案准确率出乎意料地高。**
尽管GPT-4的大部分证明的准确率较低，但在ProofWriter上它的最终选择的准确率很高（如答案列所示）。我们认为这可能是由于GPT-4在训练中暴露于数据集，可能导致一定程度的记忆。

**5.2 LeanReasoner**
| 方法 | 预训练 | 微调 | ProofWriter | FOLIO |
| --- | --- | --- | --- | --- |
| on Math Data | on our Annotation | 前提选择 | 证明 | 前提选择 | 证明 |
| GPT-4 | N/A | N/A | N/A | 15% | N/A | 10% |
| LeanReasoner | Yes | No | 56.2% | 81.3% | 0% | 23.5% | 38.2% | 0% |
| LeanReasoner | No | Intuitive | 62.5% | 100% | 99% | 54.8% | 95.2% | 71.4% |
| LeanReasoner | Yes | Intuitive

 | 75% | 100% | 99% | 71.4% | 96.8% | 85.7% |
| LeanReasoner | Yes | Concise | 75% | 100% | 99% | 83.8% | 97.4% | 85.7% |

表2：99个ProofWriter测试样本和28个FOLIO测试样本中前提选择的Recall@k和整体证明准确率的比较分析。注意这里的证明准确率不同于表1，因为它直接与最终准确率相关。评估LeanReasoner在定理证明数据和直观及简洁注释集上的预训练和微调效果。由于在提示GPT-4时复杂性较高，GPT-4基线未计算前提选择准确率。

在本节中，我们重点训练自己的模型，使用我们注释的训练数据生成策略。为了隔离错误形式化的影响，我们仅使用前一小节中准确的形式化进行测试。这样我们得到了99个ProofWriter测试示例和28个FOLIO测试示例。所有发现详见表2。

**在注释数据上微调提高了前提选择准确率。**
我们首先使用recall@1和recall@4度量标准比较前提选择的结果。recall@k度量标准定义如下：

\[ \text{recall@k} = \frac{| \text{GT\_Prem} \cap \text{Pred\_Prem}[0:k] |}{| \text{GT\_Prem} |}, \]

其中GT\_Prem表示真实前提，Pred\_Prem表示顶级预测前提。LeanReasoner仅用数学数据预训练的次优结果可能归因于数学定理证明和逻辑推理之间的领域不匹配。模型经常试图使用在数学定理证明中有用但不适用于逻辑推理的其他无关策略。此外，FOLIO的准确率明显低于ProofWriter。这种差异可能是由于FOLIO的复杂逻辑及其需要更广泛的一阶逻辑策略（如cases、have和contradiction）。相比之下，ProofWriter主要采用apply、exact和split等策略。

**在定理证明数据上预训练提高了整体准确率。**
关于整体证明结果，LeanReasoner在数学定理证明数据上预训练后，在ProofWriter和FOLIO数据集上的表现始终优于其他方法。这表明我们的模型有效地利用了数学定理证明中的逻辑“黄金”。虽然前提选择器受益于明显的提示和有限的选择范围，但策略生成的领域则要广泛得多。这个广泛的选择使得ReProver基线的证明准确率几乎可以忽略不计。此外，前提选择准确率和整体证明准确率之间存在强相关性。尽管对于像ProofWriter这样较简单的数据集，预训练的LeanReasoner的优势可能不太明显，但在更复杂的数据集如FOLIO上，其价值则更加显著。

**简洁注释在前提选择上效果更好。**
在这个小测试集上，用不同注释进行微调对前提选择和策略生成有轻微影响。用简洁注释微调时，LeanReasoner也会尝试生成简洁的证明，通常使用提供更多信息的复合策略进行前提选择。然而，在这个小测试集上的最终证明准确率并没有改变。图2展示了我们比较的三种主要方法对同一问题生成的证明。在没有预训练的情况下，模型难以识别适当的解决方法，仅试图应用下一个可用定理，缺乏明确目标。虽然直观数据提供了许多引理，有助于在编写证明时的思考过程，但这些过多的引理并不能有效地帮助LLMs生成策略。

参见图例
图2：由LeanReasoner在没有预训练（左）、在直观数据上微调（中）、在简洁数据上微调（右）生成的样本证明。

**5.3 其他基线**
| 方法 | 准确率 |
| --- | --- |
| 全训练集方法 | |
| Abs Biases Gontier et al. (2022) | 80.6% |
| MetaInduce Yang et al. (2022) | 98.6% |
| RECKONING Chen et al. (2023b) | 99.8% |
| 零样本方法 | |
| GPT-4 CoT Pan et al. (2023) | 68.1% |
| Logic-LM Pan et al. (2023) | 79.3% |
| 我们的方法（在100个样本上微调） | |
| LeanReasoner without Pretraining | 95.8% |
| LeanReasoner fine-tuned on Intuitive | 98.3% |
| LeanReasoner fine-tuned on Concise | 98.3% |

表3：在mathlib上预训练的微调LeanReasoner。全训练集方法表示模型在ProofWriter的全训练集上训练。用简洁注释微调在此数据集上并未带来任何优势。

| 方法 | 准确率 |
| --- | --- |
| 全训练集方法 | |
| Roberta Han et al. (2022b) | 62.1% |
| FOLNet Chen (2023) | 70.6% |
| 零样本方法 | |
| GPT-4 CoT Pan et al. (2023) | 70.6% |
| Logic-LM Pan et al. (2023) | 74.5% |
| Lean Z3 (SATLM) | 77.5% |
| 我们的方法（在27个样本上微调） | |
| LeanReasoner without Pretraining | 66.2% |
| LeanReasoner fine-tuned on Intuitive | 78.4% |
| LeanReasoner fine-tuned on Concise | 82.6% |

表4：从“Lean Z3”的结果来自应用于形式化Lean代码的lean-smt。全训练集方法表示模型在FOLIO的全训练集上训练。我们的方法在FOLIO上实现了最先进的性能。

我们已经证明，在定理证明数据上预训练能带来更好的性能，接下来将我们的结果与ProofWriter和FOLIO的基线进行对比。评估使用与LogicLM相同的600个问题集和整个FOLIO测试集。

我们的方法在ProofWriter上以显著较少的数据取得了近乎完美的准确率。
如表3所示，我们的方法在ProofWriter数据集上取得了近乎完美的准确率。虽然其他方法除了Logic-LM和GPT-4 COT都使用了ProofWriter的整个训练集，我们的方法仅依赖100个示例，突显了我们方法的效率。用简洁注释微调在此数据集上的最终性能没有带来任何优势。

我们的方法在FOLIO上实现了最先进的性能。
表4展示了我们在FOLIO上的表现。为了与使用Z3求解器的SATLM进行公平比较，我们在我们的形式化Lean代码上使用了lean-smt工具。该工具以“sat/unsat”的形式生成结果。在Z3中，“sat”表示“可满足”。当Z3返回“sat”结果时，表示存在一组变量值使得定理为真。另一方面，“unsat”表示“不可满足”。当Z3返回“unsat”时，表示公式本身存在矛盾，在任何情况下都无法满足。我们使用结果解释器将这些结果类似于“找到证明/未找到证明”进行解释。由于FOLIO问题证明的长度较长，我们观察到，当LeanReasoner在直观数据集上微调时，常常花费过多时间进行探索，有时会进入循环。相比之下，生成较短的证明往往更容易发现证明。虽然用简洁数据集微调时生成的策略更具挑战性，FOLIO上LeanReasoner的瓶颈在于搜索过程。

**基准测试中的挑战。**
需要注意的是，在某些情况下，问题形式化或证明生成可能出错，但最终答案仍被视为正确。一个例子是，当问题的答案是未知时，这些阶段会出现错误。在这种情况下，模型将难以证明正或负定理。然而，使用我们的结果解释器，这些实例尽管在问题处理上存在潜在问题，仍将被归类为正确。

